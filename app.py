import streamlit as st
import pandas as pd
from fetch_reddit import fetch_reddit_posts
from fetch_google_trends import fetch_google_trends
from fetch_websearch import fetch_websearch
from merge_and_filter import merge_and_filter
from analyze_gpt import analyze_topics_and_problems, analyze_solutions
from fetch_google_link import search_aliexpress

st.title("Multi-Source Problem Finder â†’ Product Ideas (Optimized)")

keyword = st.text_input("××” ×”×‘×¢×™×” ××• ×”×ª×—×•× ×©×ª×¨×¦×” ×œ×—×¤×©?", "")

if st.button("Collect & Analyze"):
    if not keyword.strip():
        st.warning("×× × ×”×–×Ÿ ××™×œ×” ××• ×ª×—×•× ×œ×—×™×¤×•×©.")
    else:
        st.write(f"××—×¤×© ×‘×¢×™×•×ª ×¢× ××™×œ×ª ××¤×ª×—: **{keyword}** ...")

        # --- GPT ×©×œ×‘ ×¨××©×•×Ÿ: ×ª×ª×™ × ×•×©××™× ---
        subtopics = analyze_topics_and_problems(keyword)
        st.write(f"×ª×ª×™ × ×•×©××™× ×œ×—×™×¤×•×©: {', '.join(subtopics)}")

        # --- ××™×¡×•×£ ××™×“×¢ ××›×œ ×”×¤×œ×˜×¤×•×¨××•×ª ---
        all_posts = []
        for topic in subtopics:
            reddit_df = fetch_reddit_posts(
                ["BuyItForLife", "LifeProTips"], keyword=topic, days=7, limit=5
            )
            trends_df = fetch_google_trends(topic)
            quora_df = fetch_websearch(topic, site="quora.com", limit=3)
            tiktok_df = fetch_websearch(topic, site="tiktok.com", limit=3)
            all_posts.append(pd.concat([reddit_df, trends_df, quora_df, tiktok_df], ignore_index=True))

        combined = pd.concat(all_posts, ignore_index=True)
        combined = merge_and_filter([combined])

        if combined.empty:
            st.warning("×œ× × ××¦××• ××¡×¤×™×§ × ×ª×•× ×™× ×œ×—×™×¤×•×© ×”×–×”.")
        else:
            st.write(f"× ××¦××• {len(combined)} ×¤×•×¡×˜×™× ×œ× ×™×ª×•×—.")

            # --- GPT ×©×œ×‘ ×©× ×™: ×‘×¢×™×•×ª ×—×•×–×¨×•×ª ---
            problems = analyze_topics_and_problems(
                keyword, combined["text_clean"].tolist(), mode="problems"
            )
            st.write("**×‘×¢×™×•×ª ×—×•×–×¨×•×ª ×©×–×•×”×•:**", problems)

            # --- GPT ×©×œ×‘ ×©×œ×™×©×™: ×¤×ª×¨×•× ×•×ª ---
            solutions = analyze_solutions(problems)
            st.write("**GPT raw output:**", solutions)

            # --- ×”×¦×’×ª ××•×¦×¨×™× (3 ×‘×œ×‘×“) ×¢× ×§×™×©×•×¨×™× ---
            rows = []
            for solution in solutions:
                product_name = solution["product"]
                score = solution["match"]
                link = search_aliexpress(product_name)
                rows.append({
                    "Product": f"**{product_name}**",
                    "Match": f"{score}%",
                    "Link": f"[ğŸ”— View Product]({link})"
                })

            output_df = pd.DataFrame(rows)
            st.write("### Recommended Products")
            st.write(output_df.to_html(escape=False, index=False), unsafe_allow_html=True)
            st.download_button("Download CSV", output_df.to_csv(index=False), "output.csv")
