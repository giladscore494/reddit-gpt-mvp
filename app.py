import streamlit as st
import pandas as pd

from fetch_reddit import fetch_reddit_posts
from fetch_google_trends import fetch_google_trends
from fetch_websearch import fetch_websearch
from merge_and_filter import merge_and_filter
from analyze_gpt import analyze_problem
from daily_trends import fetch_daily_trends

st.set_page_config(page_title="Multi-Source Problem Finder â†’ Product Ideas", layout="wide")
st.title("Multi-Source Problem Finder â†’ Product Ideas (AliExpress + Trend Check + Daily Top 10)")

# ×¤×•× ×§×¦×™×” ×œ×”×¦×’×ª ××•×¦×¨×™× ×‘×¦×•×¨×” × ×§×™×™×”
def display_products(products):
    st.subheader("××•×¦×¨×™× ××•××œ×¦×™×:")
    for idx, p in enumerate(products, start=1):
        st.write(f"**{idx}. {p['name']}** â€“ ×”×ª×××” {p['match']}% â€“ [ğŸ”— ×œ×—×¥ ×›××Ÿ]({p['link']})")
        if p.get("desc"):
            st.caption(p["desc"])

# ×—×™×¤×•×© ××•×ª×× ××™×©×™×ª ×œ×¤×™ ××™×œ×ª ××¤×ª×—
topic = st.text_input("××” ×”×‘×¢×™×” ××• ×”×ª×—×•× ×©×ª×¨×¦×” ×œ×—×¤×©?")
if st.button("×—×¤×© ×¤×ª×¨×•× ×•×ª"):
    if topic.strip():
        st.write(f"××—×¤×© ×‘×¢×™×•×ª ×¢× ××™×œ×ª ××¤×ª×—: {topic} ...")

        # ××§×•×¨×•×ª ×©×•× ×™× (Reddit, Google Trends, TikTok, Quora)
        reddit_df = fetch_reddit_posts(["BuyItForLife", "LifeProTips"], keyword=topic, days=7, limit=5)
        trends_df = fetch_google_trends(topic)
        tiktok_df = fetch_websearch(topic, site="tiktok.com", limit=3)
        quora_df = fetch_websearch(topic, site="quora.com", limit=3)

        combined = pd.concat([reddit_df, trends_df, tiktok_df, quora_df], ignore_index=True)
        combined = merge_and_filter(combined)

        if combined.empty:
            st.warning("×œ× × ××¦××• ×¤×•×¡×˜×™× ×¨×œ×•×•× ×˜×™×™×")
        else:
            st.write("× ××¦××• ×‘×¢×™×•×ª ×—×•×–×¨×•×ª ×©×–×•×”×•:")
            st.write(combined["text_clean"].unique().tolist())

            # × ×™×ª×•×— ×¤×ª×¨×•× ×•×ª
            recommended_products = analyze_problem(topic)
            if recommended_products:
                display_products(recommended_products)
            else:
                st.error("×œ× × ××¦××• ××•×¦×¨×™× ×¨×œ×•×•× ×˜×™×™× ×œ×‘×¢×™×” ×–×•.")

# ×›×¤×ª×•×¨ ×œ×”×¦×’×ª 10 ×‘×¢×™×•×ª ×˜×¨× ×“×™×•×ª (×œ× ×§×©×•×¨ ×œ××™×œ×ª ×”×—×™×¤×•×©)
if st.button("Top 10 ×‘×¢×™×•×ª ×˜×¨× ×“×™×•×ª ×”×©×‘×•×¢"):
    st.write("×‘×•×“×§ ×˜×¨× ×“×™× ×›×œ×œ×™×™×...")
    daily_products = fetch_daily_trends()
    if daily_products:
        st.write("×˜×•×¤ 10 ×‘×¢×™×•×ª ×˜×¨× ×“×™×•×ª ×”×©×‘×•×¢ ×©× ×™×ª×Ÿ ×œ×¤×ª×•×¨ ×‘××•×¦×¨:")
        for idx, item in enumerate(daily_products, start=1):
            st.write(f"**{idx}. {item['problem']}** â€“ [××•×¦×¨ ×œ×“×•×’××”]({item['link']})")
            st.caption(item['desc'])
    else:
        st.warning("×œ× × ××¦××• ×˜×¨× ×“×™× ×–××™× ×™× ×›×¨×’×¢.")
